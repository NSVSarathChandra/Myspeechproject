\documentclass[11pt]{beamer}
\usetheme{Boadilla}
\usepackage[utf8]{inputenc}
\usepackage[icelandic]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{N SAI VENKATA SARATH CHANDRA 
CC20MTECH14001}
\title{AI/ML SPEECH RECOGNITION PROJECT}
\institute[IIT-H]
{
\\Guided by:\\Dr G.V.V.SHARMA
}
\setbeamercovered{transparent} 

\setbeamertemplate{navigation symbols}{} 
 


\date{28-12-2020} 
\subject{EE5600/AI5600} 
\begin{document}


\begin{frame}
\titlepage
\end{frame}



\begin{frame}
\frametitle{INTRODUCTION}
\begin{enumerate}
    \item Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers.
    \item This Speech command recognition model is based on concepts of Convolution, LSTM and Attention.
\end{enumerate}




 



\end{frame}

\begin{frame}{Create Data}
\frametitle{CREATE DATA}
\begin{enumerate}
 \item Setting 16KHz as sampling rate
    \item Recording 80 utterances of each command.
    \item Trimming each utterance to one second.
    \item Saving samples of each command in different folders\\
         Dataset/forward\\
         Dataset/back\\
         Dataset/left\\
         Dataset/right\\
         Dataset/stop
    \item Using Audacity to record the voice samples for words forward,back,left,right,stop.
\end{enumerate}


\end{frame}

\begin{frame}
{LOAD DATA}
\begin{enumerate}
    \item Load Data using numpy files.
    \item Wavefile, librosa etc can also be used.
\end{enumerate}
   
\end{frame}


\begin{frame}
{SPLIT DATASET}
Carrying out a stratified split of the dataset into train and test set with 20% as test samples.
Set a random seed for reproducing the split.
\end{frame}


\begin{frame}
{AUGMENT DATA}
Augment each audio sample by time shifting in 25000 length vectors filled with zeros.

Take steps of 500 to create 18 files per sample
\end{frame}


\begin{frame}
{FEATURE EXTRACTION}
\begin{enumerate}
    \item MFCCs are most prominent features used in audio processing.
    \item Normalizing the MFCCs over the frequency axis is found to reduce effect of noise.
    \item Kapre is a python package that provides layers for audio processing that are compatible with keras and utilize GPU for faster processing. Kapre provides us with a layer basically
\end{enumerate}



\end{frame}




\begin{frame}
{BUILDING MODEL: DESCRIPTION}
\begin{enumerate}
    \item Using convolutional layers ahead of LSTM is shown to improve performance in several research papers.
    \item Batch normalization layers are added to improve convergence rate.
    \item Using Bidirectional LSTM is optimal when complete input is available. But this increases the runtime two-fold.
    \item Final output sequence of LSTM layer is used to calculate importance of units in LSTM using a FC layer.
    \item Then take the dot product of unit importance and output sequences of LSTM to get attention scores of each time step.
    \item Take the dot product of Attention scores and the output sequences of LSTM to get attention vector.
    \item Add an additional FC Layer and then to output Layer with SoftMax Activation.
\end{enumerate}
\end{frame}

\begin{frame}
{RUN}
\begin{itemize}
    \item The Code is written using GOOGLE COLAB.
    \item Open Colabnotebook.ipynb and changing Runtime to GPU.
    \item Upload file to Colab.
    \item Change datadir in all cells to point to Dataset.
    \item Run the cells in order in the notebook.
\end{itemize}
\end{frame}



\begin{frame}
{TESTING}
\begin{enumerate}
    \item Augment the test set same as training set.
    \item Extract MFCCs using same method as training set
    \item Test set is passed as validation set to fit method of model.
    \item The performance of model on test set is calculated after every epoch.
\end{enumerate}

\end{frame}



\begin{frame}
{TEST STEPS}
\begin{enumerate}
    \item Locating the model.h5 file.
    \item Start speaking when mike is seen at the bottom right of the task bar.
    
\end{enumerate}
    
\end{frame}

\begin{frame}
{VISUALIZE ATTENTION}
\begin{enumerate}
    \item Building a sub model from the trained model. 
    \item Taking same input layer and adding ‘AttentionSoftmax’ layer as additional output layer.
    \item Passing MFCCs of test samples to predict method.
    \item Now plotting log of attention Scores and corresponding input vector before taking MFCCs on different axes.
    \end{enumerate}
\end{frame}
\begin{frame}
{REFERENCES}
\begin{enumerate}
    \item A neural attention model for speech command recognition - by Douglas Coimbra de Andrade, Sabato Leo, Martin Loesener Da Silva Viana, Christoph Bernkopf

    \item GITHUB:https://github.com/PradeepMoturi/Speech-Command-Model/tree/master/Data/Pradeep16
    \item GITHUB:https://github.com/gadepall/aiml/blob/master/Speech-Command-Model/Report.pdf
\end{enumerate}
\end{frame}
\end{document}